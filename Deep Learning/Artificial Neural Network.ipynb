{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cbe2462",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6de6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve,auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "import import_ipynb\n",
    "from DataPreProcessing import new_df,X,y,X_train, X_test, y_train,y_test,sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133c457",
   "metadata": {},
   "source": [
    " # Building and Training a Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d77ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(20, input_shape=(4,), activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c974905",
   "metadata": {},
   "source": [
    "## To Check if the model is overfitting or underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5462d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "y_train_pred_ann = model.predict(X_train)\n",
    "y_val_pred_ann = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary format (0 or 1)\n",
    "y_train_pred_ann_binary = np.where(y_train_pred_ann > 0.5, 1, 0)\n",
    "y_test_pred_ann_binary = np.where(y_val_pred_ann > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_accuracy_ann = accuracy_score(y_train, y_train_pred_ann_binary)\n",
    "val_accuracy_ann = accuracy_score(y_test, y_test_pred_ann_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066cb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = round(train_accuracy_ann)\n",
    "val_accuracy = round(val_accuracy_ann)\n",
    "print(\"Training Accuracy:\", train_accuracy )\n",
    "print(\"Validation Accuracy:\",  val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ff257",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_accuracy > val_accuracy:\n",
    "    print(\"The model may be overfitting.\")\n",
    "elif train_accuracy < val_accuracy:\n",
    "    print(\"The model may be underfitting.\")\n",
    "else:\n",
    "    print(\"The model's performance on training and validation sets are similar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26545bbb",
   "metadata": {},
   "source": [
    "# Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ca6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[1,9839.64, 170136.0,160296.36]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[4,181.00, 181.00,0.00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a50c5",
   "metadata": {},
   "source": [
    "# Prediciting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5   #A threshold of 0.5 is often chosen when there is no specific preference for precision or recall. \n",
    "                  #It provides a balanced trade-off between the two metrics.\n",
    "y_pred_binary = np.where(y_pred >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccca786",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.concatenate((y_pred_binary.reshape(len(y_pred_binary), 1),y_test.reshape(len(y_test), 1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2fb8f",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3469a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred_binary)\n",
    "round(accuracy*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b2856",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "'''\n",
    "0- No Fraud\n",
    "1- Fraud\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db62e32",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Make predictions on the test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "ann_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ANN Classifier (area = %0.2f)' % ann_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ANN_ROC')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed74da8",
   "metadata": {},
   "source": [
    "# Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f613cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_train_ann = model.predict(X_train)\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision_ann, recall_ann, _ = precision_recall_curve(y_train, y_prob_train_ann)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.fill_between(recall_ann, precision_ann)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Train Precision-Recall curve\")\n",
    "plt.show()\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "auc_prc = auc(recall_ann, precision_ann)\n",
    "print(\"AUC-PRC:\", auc_prc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789840e",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07dbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116854b5",
   "metadata": {},
   "source": [
    "# Calibration Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9acb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the training set\n",
    "y_prob_train_ann = model.predict(X_train)\n",
    "\n",
    "# Calculate calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_train, y_prob_train_ann, n_bins=10)\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.plot(prob_pred, prob_true, marker='o', linestyle='-', label='Calibration Curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "plt.xlabel('Mean Predicted Probability')\n",
    "plt.ylabel('Fraction of Positives')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
